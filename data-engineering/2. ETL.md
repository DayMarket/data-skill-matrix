# 2. ETL

Этот трек посвящен навыкам проектирования, разработки и поддержки ETL-пайплайнов, включая работу с распределенными системами, оркестрацию данных и оптимизацию производительности.

## DE1 (Junior)
- Я понимаю, зачем нужны распределённые вычисления в Spark и когда их выбирать вместо однопоточных инструментов.
- Я понимаю концепцию DAG в Airflow, назначение тасков, расписание и ретраи и могу объяснить, когда применять оркестрацию.
- Я создаю DAG, используя PythonOperator, BashOperator и Sensor; настраиваю расписание и ретраи.
- Я запускаю spark batch‑джобы до ≈ 50 GB данных, используя DataFrame API и базовые трансформации.

## DE2 (Middle)
- Я строю DAG, использую Branch/Trigger Rules, XCom и TaskGroup, интегрируюсь с S3, БД и внешними API.
- Я читаю и трансформирую данные из таблиц Iceberg, оптимизирую partitioning, persist и broadcast joins.

## DE3 (Middle +)
- Я проектирую многоэтапные пайплайны с Sensor‑triggered и динамически генерируемыми тасками, внедряю DAG‑versioning и тесты; применяю Pools, Queues и Priority Weights для балансировки воркеров.
- Я записываю данные в Iceberg‑таблицы, настраиваю partitioning и поддерживаю snapshot isolation; конфигурирую executors и shuffle service.

## DE4 (Senior)
- Я оптимизирую производительность оркестрации, настраиваю метрики/алерты в Prometheus/Grafana и повышаю стабильность ETL-пайплайнов делая их более надежными.
- Я оптимизирую Iceberg (metadata compaction, manifest merge), управляю Structured Streaming и ресурсами кластера Spark K8s.
- Я создаю многоразовые ETL‑frameworks, custom Operators/Hooks, UI‑плагины и обучаю команды best‑practices.

## DE5 (Staff)
- Я управляю lakehouse‑слоем Iceberg, обеспечиваю schema evolution и time‑travel при объёмах > 10 TB; автоматизирую CI/CD для пайплайнов.
- Я формирую и документирую архитектуру оркестрации данных, политики владения DAG (code‑owners, review rules, CI‑гейты); формирую рекомендации по versioning, тестированию и security‑context; фиксирую решения в ADR и провожу архитектурные ревью.
- Я формирую roadmap вычислительных движков (Spark/Trino), управляю cost‑моделью кластера, оцениваю новые фичи Iceberg и провожу PoC. 